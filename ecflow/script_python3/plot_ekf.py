import argparse, glob, sys, csv, os
import numpy as np, pandas as pd, datetime as dt
import matplotlib, matplotlib.pyplot as plt, matplotlib.dates as mdates
from matplotlib.lines import Line2D

# -------------------------------------------------------------------------------------
# DESCRIPTION - 15/12/2020
# -------------------------------------------------------------------------------------
# The script reads ekf files generated by "read_ekf.py" and generates several plots:
#   - last24h.png: plot number and percentage of active, passive and rejected
#       observations for each report in each assimilation cycle of the last 24 hours;
#   - last30d.png: plot number and percentage of active, passive and rejected
#       observations for each report in each day of the last 30 days (cumulating data
#       of each assimilation cycles over each day);
#   - last365d.png: same as 'last30d.png' but for the last 365 days;
#   - last30d_REP.png: number and percentage of observation types for the report REP
#       in each day of the last 30 days (cumulating data of each assimilation cycles 
#       over each day);
#   - last365d_REP.png: same as 'last30d_REP.png' but for the last 365 days;
#   - last30d_REP_check.png: number and percentage of reasons why (checks) the
#       observations of report REP are set passive or rejected.
#   - last365d_REP_check.png: same as 'last30d_REP_check.png' but for the last 365 
#       days;
# Report to be considered are specified by --report.
#
# Note that, to plot data, one can use two functions: "pyplot.stackplot" and 
# "pyplot.bar". The former approach is faster and leads to results similar to # those 
# obtained by the latter (in particular exploiting the "step" parameter). However, to 
# make it works in the "right way" as "pyplot.bar", some accrocchi are necessary. 
# Therefore, here it is decided to employ the slower but cleaner approach of 
# "pyplot.bar". In case you change your mind about it, remember that part of the 
# inaccurancies of this method can be eliminated by replacing zeros with NaNs (see 
# "calc_perc" and "zeros_to_nan" functions).


# -------------------------------------------------------------------------------------
# VARIABLES AND FUNCTIONS
# -------------------------------------------------------------------------------------
# Colors for summary (state) plots, that is for active, passive and rejected 
# observations (last24h.png, last30d.png, last365d.png)
cols_st = [[ 57/255,175/255, 54/255],
           [ 255/255,255/255, 51/255],
           [228/255, 26/255, 28/255]]

# Colors for observation variables and checks (last30d_REP.png, last365d_REP.png,
# last30d_REP_check.png, last365d_REP_check.png)
cols_ot = [[ 31/255,120/255,180/255],
           [255/255,127/255,  0/255],
           [ 51/255,160/255, 44/255],
           [227/255, 26/255, 28/255],
           [166/255,206/255,227/255],
           [178/255,223/255,138/255],
           [251/255,154/255,153/255],
           [253/255,191/255,111/255],
           [202/255,178/255,214/255],
           [106/255, 61/255,154/255],
           [255/255,255/255,153/255],
           [177/255, 89/255, 40/255],
           [180/255,180/255,180/255],
           [120/255,120/255,120/255],
           [ 60/255, 60/255, 60/255]]

# Format of dates in x-axis for 24 hours, 30 days and 365 days plots
fmt_24h  = mdates.DateFormatter("%d %b %H:%M")
fmt_30d  = mdates.DateFormatter("%d %b %Y")
fmt_365d = mdates.DateFormatter("%d %b %Y")

# plot general fontsize and resolution
size     = 24
font     = {'size': size}
dpi      = 120
plt.rc('font', **font)

# Command line input
def command_line():
    parser = argparse.ArgumentParser(description = 'KENDA DIAGNOSTIC - PLOT DATA.     \
                        The script read diagnostic files generated by read_ekf.py and \
                        plot contained data of the last 24 hours, 30 days and 365     \
                        days.')
    parser.add_argument('--folder', default = ".",   type = str,
                        help = 'Folder in which files generated by read_ekf.py are    \
                                stored (defalut: current directory)')
    parser.add_argument('--report', default = ["AIREP", "SYNOP", "TEMP"],
                        nargs='+',  type = str,
                        help = 'Blank space separated list of observation reports to  \
                                be ploteed (default: AIREP SYNOP TEMP)')
    parser.add_argument('--lencyc', default = 3,     type = int,
                        help = 'Length of assimilation cycles in hours')
    parser.add_argument('--last_date', default = "", type = str,
                        help = 'Last date to be plotted in the format YYYYMMDDHH')
    return parser.parse_args()


# Read data from csv file. Parameters: 
#   - fname      = file name
#   - option     = 'dict'   : to store file as a dictionary, considering each row as
#                             if the first element is the key and the second the value
#                             (key: value)
#                  'summary': to acquire files containing 'summary' information
#                  'checks' : to acquire files containing 'checks'  information
#   - check_list = list of headers for checks (that is, headers of the file containing
#                  checks information but without 'Date', 'Time' or other entries not
#                  linked to the count of checks).
def read_from_csv(fname, option, check_list=None):
    # Read the file
    with open(fname, 'r') as csvfile:
        # Read the file as a dictionary for each row (key: value} and
        # return it
        if option == 'dict':
            reader = csv.reader(csvfile)
            mydict = {int(rows[0]):rows[1] for rows in reader}
            return mydict
        # Read the file as a dictionary for each column {header: value)
        # to be decomposed, after, into arrays
        else:
            reader = csv.DictReader(csvfile)
            data = {}
            for row in reader:
                for header, value in row.items():
                    try:
                        data[header].append(value)
                    except KeyError:
                        data[header] = [value]

    # Store date and time in a list of datetime objects and other data 
    # according to 'option'
    date     = np.array(data['Date'])
    time     = np.array(data['Time'])
    datetime = np.array([dt.datetime.strptime("%s %s" %(date[i], time[i]),
                        '%Y%m%d %H%M') for i in range(len(date))])
    if option == 'summary':
        tot_obs = np.array(data['Total'],    dtype=int)
        act_obs = np.array(data['Active'],   dtype=int)
        pas_obs = np.array(data['Passive'],  dtype=int)
        rej_obs = np.array(data['Rejected'], dtype=int)
        return datetime, tot_obs, act_obs, pas_obs, rej_obs
    elif option == 'checks':
        for cn in check_list:
            chk_cn  = np.array(data[cn], dtype=int)
            if cn == check_list[0]:
                checks = chk_cn
            else:
                checks = np.c_[checks, chk_cn]
        return datetime, checks
 

# Get the substring of 's' between substrings 'first' and 'last'.
def find_between(s, first, last):
    try:
        start = s.index( first ) + len( first )
        end = s.index( last, start )
        return s[start:end]
    except ValueError:
        return ""


# Select last 365 days and 30 days of data, summing over days. Parameters:
#   - inp_dt  = list of datetime aoociated to 'inp_arr' (generally read from
#               the csv file)
#   - inp_arr = array containing data 
#   - option  = 'state': if 'inp_arr' contains total, active, passive and 
#                        rejected observations
#               'check': if 'inp_arr' contains count of check por passive
#                        or rejected observations
def select_daydata(inp_dt, inp_arr, option):
    # Initialize variables
    dt_ana = dt_365dbf
    j, k   = 0, 0
    if   option == 'state':
        out_arr_30d  = np.zeros(diff_30d) 
        out_arr_365d = np.zeros(diff_365d)
    elif option == 'check':
        out_arr_30d  = np.zeros((diff_30d,  len(chk_dict)))
        out_arr_365d = np.zeros((diff_365d, len(chk_dict)))

    # Loop over days
    while dt_ana <= dt_prev_day:
        # Select data for the specified date
        day_data = inp_arr[(inp_dt >= dt_ana) & (inp_dt <= dt_ana+delta_day_lencyc)]

        # Sum all day data and save for 365 days plot
        if   option == 'state':
            out_arr_365d[j]    = np.sum(day_data)
        elif option == 'check':
            out_arr_365d[j, :] = np.sum(day_data, axis=0)

        # Sum all day data and save for 30 days plot
        if dt_ana >= dt_30dbf:
            if   option == 'state':
                out_arr_30d[k]    = np.sum(day_data)
            elif option == 'check':
                out_arr_30d[k, :] = np.sum(day_data, axis=0)
            k += 1

        # Update dt_ana
        j      += 1
        dt_ana += dt.timedelta(days=1)

    return out_arr_30d, out_arr_365d


# Compute array division 'a/b' and set = 0 when dividing by 0. If 'nan' is True,
# rows consisting only of 0 are replaced by 'np.nan'
def calc_perc(a, b, nan=False):
    result = np.divide(a, b, out=np.zeros_like(a, dtype=float), where=b!=0) * 100
    if nan: result = zeros_to_nan(result, 'rows')

    return result


# Replace rows or columns (depending on ax) of 'array' consisting only of 0 by nan
def zeros_to_nan(array, ax):
    array_out = array.copy()
    if ax == 'rows':
        zeros_rows = np.where(~array_out.any(axis=1))[0]
        for zr in zeros_rows:
            array_out[zr, :] = np.nan
    elif ax == 'cols':
        zeros_cols = np.where(~array_out.any(axis=0))[0]
        for zc in zeros_cols:
            array_out[:, zc] = np.nan

    return array_out


# Axis labels and ticks for subplots. Parameters:
#   - ax           = axis to which apply modifications
#   - xmin, xmax   = limits for x-axis (a small white space before xmin and after xmax
#                    is added, dependeng on the width of the interval)
#   - ymin, ymax   = limits for y-axis
#   - title        = title of the subplot (None = no title)
#   - xlabel       = label of x-axis      (None = no title)
#   - ylabel       = label of y-axis      (None = no title)
#   - xaxis_values = if True, x-axis ticks are added
#   - xfreq        = frequency of x-axis ticks
#   - xfmt         = format    of x-axis ticks
def axis_labels_ticks(ax, xmin, xmax, ymin, ymax, title=None, xlabel=None, 
                      ylabel=None, xaxis_values=False, xfreq=None, xfmt=None):
    # Title
    if title is not None: ax.set_title(title, fontsize=size+3)

    # Label for y-axis
    if ylabel is not None: ax.set_ylabel(ylabel, fontsize=size)

    # Label for x-axis
    if xlabel is not None: ax.set_xlabel(xlabel, fontsize=size)

    # Define extra white space before xmin and after xmax
    if   (xmax-xmin).days <= 3:
        extra_sp = dt.timedelta(hours=lencyc/2)
    elif (xmax-xmin).days > 3 and (xmax-xmin).days <= 33:
        extra_sp = dt.timedelta(hours=12)
    else:
        extra_sp = dt.timedelta(hours=24)

    # Format x-axis (remove ticks if xaxis_values = False)
    if xaxis_values:
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=90, fontsize=size-5)
        ax.set_xticks(pd.date_range(xmin, xmax, freq=xfreq))
        ax.xaxis.set_major_formatter(xfmt)
    else:
        ax.tick_params(axis='x', which='both', bottom=False, top=False, 
                      labelbottom=False)
    ax.set_xlim(xmin-extra_sp, xmax+extra_sp)

    # Format y-axis
    plt.setp(ax.yaxis.get_majorticklabels(), fontsize=size-2)
    ax.set_ylim(ymin, ymax)
    if ymax >= 10000:
        ax.ticklabel_format(axis='y', style='sci', scilimits=(0,0), useLocale=True)
        ax.yaxis.get_offset_text().set_fontsize(size-2)

    return ax


# Plot superior title and save figure. Parameters:
#   - figure   = figure object
#   - prefix   = string to put at the beginning of the title
#   - interval = time interval of data ('24 hours', '30 days', '365 days')
#   - fdate    = first date of the interval
#   - ldate    = last  date of the interval
def plot_title_and_save(figure, prefix, interval, fdate, ldate, outname):
    # Plot title
    if interval == '24 hours':
        st = figure.suptitle('%s in the last %s (from %s to %s)' %(prefix, interval, 
                             fdate.strftime("%d/%m/%y at %H UTC"),
                             ldate.strftime("%d/%m/%y at %H UTC")), fontsize=size+6)
    else:
        st = figure.suptitle('%s in the last %s (from %s to %s)' %(prefix, interval,
                             fdate.strftime("%d/%m/%y"), ldate.strftime("%d/%m/%y")),
                             fontsize=size+6)
    # Set position
    st.set_y(0.96)

    # Save plot and close
    figure.savefig(outname, bbox_inches='tight')
    plt.close(figure)

    return None


# Create bar plot with stacked data, employing the rows of 'data' array. Parameters:
#   - ax     = axis to be used for the plot
#   - x      = x-axis values
#   - data   = array containing data to plot (each row will be plotted separately
#              employing as 'bottom' the sum of the previous ones)
#   - colors = list of colors associated at each row of 'data'.
#   - width  = [optional] width of each bar
def stack_barplot(ax, x, data, colors, width=1):
    nrows, ncols = np.shape(data)
    bot = np.zeros(ncols)
    for nr in range(nrows):
        ax.bar(x, data[nr, :], width, color=colors[nr], bottom=bot)
        bot = bot + data[nr, :]

    return None


# -------------------------------------------------------------------------------------
# INITIALIZE SOME VARIABLES
# -------------------------------------------------------------------------------------
# Read variables from commad line
args = command_line()
folder, report, lencyc, last_date = args.folder, args.report, args.lencyc, \
                                    args.last_date
if len(report) == 0:
    sys.exit("ERROR! You must specify a valid string for --report")

# Import dictionaries for checks and observations
chk_dict = read_from_csv('dictionary_checks.csv', 'dict')
var_dict = read_from_csv('dictionary_variables.csv', 'dict')

# Define header for 'summary' and 'checks' files
head_sum = ['Date', 'Time', 'Total', 'Active', 'Passive', 'Rejected']
head_chk = ['Date', 'Time']
chk_list = []
for i in range(len(chk_dict)):
    chk_list.append('c%s' %i)
head_chk = head_chk + chk_list

# Time interval for  24h plot 
dt_last     = dt.datetime.strptime(last_date, '%Y%m%d%H')
dt_24hbf    = dt_last - dt.timedelta(hours=24-lencyc)

# Time interval for  30d plot (consider the penultimate day to have a complete day of
# KENDA cycles)
dt_prev_day = dt.datetime(dt_last.year, dt_last.month, dt_last.day, 0)
dt_30dbf    = dt_prev_day - dt.timedelta(days=30) + dt.timedelta(hours=lencyc)

# Time interval for 365d plot (consider the penultimate day as for 30d plots)
dt_365dbf   = dt_prev_day - dt.timedelta(days=365) + dt.timedelta(hours=lencyc)

# Retrieve datetime variables necessary for all 30d and 365d plots
diff_365d        = (dt_prev_day - dt_365dbf).days + 1
diff_30d         = (dt_prev_day -  dt_30dbf).days + 1
lst30d_dt        = pd.date_range(dt_30dbf,  dt_prev_day, freq='1d')
lst365d_dt       = pd.date_range(dt_365dbf, dt_prev_day, freq='1d')
delta_day_lencyc = dt.timedelta(hours=24-lencyc)


# -------------------------------------------------------------------------------------
# PLOT SUMMARY DATA FOR LAST 24 HOURS, 30 DAYS AND 365 DAYS 
# -------------------------------------------------------------------------------------
# Initialize plots
print("\n------------------------------------------------------------")
print("PLOT")
print("------------------------------------------------------------")
print('SUMMARY DATA:')
fig_24h,  ax_24h  = plt.subplots(nrows=2, ncols=len(report), 
                                 figsize=(9*len(report), 13), dpi=dpi)
fig_24h.subplots_adjust(hspace=0.1, wspace=0.15)
fig_30d,  ax_30d  = plt.subplots(nrows=2, ncols=len(report),
                                 figsize=(9*len(report), 13), dpi=dpi)
fig_30d.subplots_adjust(hspace=0.1, wspace=0.15)
fig_365d, ax_365d = plt.subplots(nrows=2, ncols=len(report),
                                 figsize=(9*len(report), 13), dpi=dpi)
fig_365d.subplots_adjust(hspace=0.1, wspace=0.15)

# Add fake asis in case len(report) is 1
if len(np.shape(ax_24h))  == 1:   ax_24h  = ax_24h[:, np.newaxis]
if len(np.shape(ax_30d))  == 1:   ax_30d  = ax_30d[: ,np.newaxis]
if len(np.shape(ax_365d)) == 1:   ax_365d = ax_365d[:,np.newaxis]

# Loop over observation type
for o_type in report:
    # Get index of element in list
    print('- %s:' %o_type)
    ind = report.index(o_type)

    # Import all data stored in csv file
    fname = "%s/%s.csv" %(folder, o_type)
    datetime, tot_obs, act_obs, pas_obs, rej_obs = read_from_csv(fname, 'summary')
 
    # Select last 24 hours of data
    lst24h_dt   = datetime[(datetime >= dt_24hbf) & (datetime <= dt_last)]
    lst24h_tot  = tot_obs[(datetime  >= dt_24hbf) & (datetime <= dt_last)]
    lst24h_act  = act_obs[(datetime  >= dt_24hbf) & (datetime <= dt_last)]
    lst24h_pas  = pas_obs[(datetime  >= dt_24hbf) & (datetime <= dt_last)]
    lst24h_rej  = rej_obs[(datetime  >= dt_24hbf) & (datetime <= dt_last)]

    # If no observation is available in the last 24 hours, a fake array consisting of
    # zeros is created, in order to avoid problems when computing 'maxval'
    if len(lst24h_tot) == 0:
        lst24h_tot = np.zeros(lencyc)

    # Select last 365 days and 30 days of data, summing over days
    lst30d_tot, lst365d_tot = select_daydata(datetime, tot_obs, 'state')
    lst30d_act, lst365d_act = select_daydata(datetime, act_obs, 'state')
    lst30d_pas, lst365d_pas = select_daydata(datetime, pas_obs, 'state')
    lst30d_rej, lst365d_rej = select_daydata(datetime, rej_obs, 'state')

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # PLOT SUMMARY DATA FOR LAST 24H: NUMBER OF OBSERVATIONS AND PERCENTAGE
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # Number of observations: Create bar plot
    print("   + Plot last 24 hours of data, from %s to %s" %(dt_24hbf, dt_last))
    lst24h_data = np.vstack([lst24h_act, lst24h_pas, lst24h_rej])
    stack_barplot(ax_24h[0,ind], lst24h_dt, lst24h_data, cols_st, width=0.025*lencyc)

    # Number of observations: Set title, labels and ticks
    maxval = 1.1*np.amax(lst24h_tot) + 1
    if ind == 0: 
        axis_labels_ticks(ax_24h[0,ind], dt_24hbf, dt_last, 0, maxval, title=o_type, 
                          ylabel='Number of observations')
    else:
        axis_labels_ticks(ax_24h[0,ind], dt_24hbf, dt_last, 0, maxval, title=o_type)

    # Percentage: compute values and create bar plot
    lst24h_data_pc = calc_perc(lst24h_data, lst24h_tot[None, :])
    stack_barplot(ax_24h[1,ind], lst24h_dt, lst24h_data_pc, cols_st, width=0.025*lencyc)

    # Percentage: Set title, labels and ticks
    if ind == 0:
        axis_labels_ticks(ax_24h[1,ind], dt_24hbf, dt_last, 0, 100, 
                          xlabel='Date and Time', ylabel='Percentage [%]', 
                          xaxis_values=True, xfreq='%sh' %lencyc, xfmt=fmt_24h)
    else:
        axis_labels_ticks(ax_24h[1,ind], dt_24hbf, dt_last, 0, 100,
                          xlabel='Date and Time', xaxis_values=True, 
                          xfreq='%sh' %lencyc, xfmt=fmt_24h)

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # PLOT SUMMARY DATA FOR LAST 30 DAYS: NUMBER OF OBSERVATIONS AND PERCENTAGE
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # Number of observations: Create stacked histogram
    print("   + Plot last  30 days of data, from %s to %s" %(dt_30dbf, dt_prev_day))
    lst30d_data = np.vstack([lst30d_act, lst30d_pas, lst30d_rej])
    stack_barplot(ax_30d[0,ind], lst30d_dt, lst30d_data, cols_st)

    # Number of observations: Set title, labels and ticks
    maxval   = 1.1*np.amax(lst30d_tot)
    if ind == 0:
        axis_labels_ticks(ax_30d[0,ind], dt_30dbf, dt_prev_day, 0, maxval, title=o_type,
                          ylabel='Number of observations')
    else:
        axis_labels_ticks(ax_30d[0,ind], dt_30dbf, dt_prev_day, 0, maxval, title=o_type)

    # Percentage: compute values and create stacked histogram
    lst30d_data_pc = calc_perc(lst30d_data, lst30d_tot[None, :])
    stack_barplot(ax_30d[1,ind], lst30d_dt, lst30d_data_pc, cols_st)

    # Percentage: Set title, labels and ticks
    if ind == 0:
        axis_labels_ticks(ax_30d[1,ind], dt_30dbf, dt_prev_day, 0, 100,
                          xlabel='Date and Time', ylabel='Percentage [%]',
                          xaxis_values=True, xfreq='3d', xfmt=fmt_30d)
    else:
        axis_labels_ticks(ax_30d[1,ind], dt_30dbf, dt_prev_day, 0, 100,
                          xlabel='Date and Time', xaxis_values=True,
                          xfreq='3d', xfmt=fmt_30d)

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # PLOT SUMMARY DATA FOR LAST 365 DAYS: NUMBER OF OBSERVATIONS AND PERCENTAGE
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # Number of observations: Create stack plot
    print("   + Plot last 365 days of data, from %s to %s" %(dt_365dbf, dt_prev_day))
    lst365d_data = np.vstack([lst365d_act, lst365d_pas, lst365d_rej])
    stack_barplot(ax_365d[0,ind], lst365d_dt, lst365d_data, cols_st)

    # Number of observations: Set title, labels and ticks
    maxval   = 1.1*np.amax(lst365d_tot)
    if ind == 0:
        axis_labels_ticks(ax_365d[0,ind], dt_365dbf, dt_prev_day, 0, maxval, title=o_type,
                          ylabel='Number of observations')
    else:
        axis_labels_ticks(ax_365d[0,ind], dt_365dbf, dt_prev_day, 0, maxval, title=o_type)

    # Percentage: compute values and create stack plot
    lst365d_data_pc = calc_perc(lst365d_data, lst365d_tot[None, :])
    stack_barplot(ax_365d[1,ind], lst365d_dt, lst365d_data_pc, cols_st)

    # Percentage: Set title, labels and ticks
    if ind == 0:
        axis_labels_ticks(ax_365d[1,ind], dt_365dbf, dt_prev_day, 0, 100,
                          xlabel='Date and Time', ylabel='Percentage [%]',
                          xaxis_values=True, xfreq='30d', xfmt=fmt_365d)
    else:
        axis_labels_ticks(ax_365d[1,ind], dt_365dbf, dt_prev_day, 0, 100,
                          xlabel='Date and Time', xaxis_values=True,
                          xfreq='30d', xfmt=fmt_365d)

# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
# PLOT SUMMARY DATA FOR LAST 24 HOURS, 30 DAYS AND 365 DAYS: LEGEND, TITLE, SAVE
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
# Legend
handles_24h = []
handles_24h.append(Line2D([0], [0], color=cols_st[0], linewidth=15, label="Assimilated"))
handles_24h.append(Line2D([0], [0], color=cols_st[1], linewidth=15, label="Passive"))
handles_24h.append(Line2D([0], [0], color=cols_st[2], linewidth=15, label="Rejected"))
leg_24h = fig_24h.legend(loc='center', handles=handles_24h, handlelength=3, ncol=3,
                     bbox_to_anchor=(0.5, -0.1), prop={'size': size+2})
fig_24h.gca().add_artist(leg_24h)
leg_30d = fig_30d.legend(loc='center', handles=handles_24h, handlelength=3, ncol=3,
                     bbox_to_anchor=(0.5, -0.1), prop={'size': size+2})
fig_30d.gca().add_artist(leg_30d)
leg_365d = fig_365d.legend(loc='center', handles=handles_24h, handlelength=3, ncol=3,
                     bbox_to_anchor=(0.5, -0.1), prop={'size': size+2})
fig_365d.gca().add_artist(leg_365d)

# Plot title and save
plot_title_and_save(fig_24h,  "Available observations", '24 hours', dt_24hbf, dt_last,
                    'last24h.png')
plot_title_and_save(fig_30d,  "Available observations", '30 days',  dt_30dbf, 
                    dt_prev_day-dt.timedelta(days=1), 'last30d.png')
plot_title_and_save(fig_365d, "Available observations", '365 days', dt_365dbf, 
                    dt_prev_day-dt.timedelta(days=1), 'last365d.png')


# -------------------------------------------------------------------------------------
# PLOT OBSERVATION DATA FOR EACH REPORT
# -------------------------------------------------------------------------------------
print('\nOBSERVATION DATA FOR EACH REPORT')
for o_type in report:
    # Initialize plots
    print('- %s:' %o_type)
    fig_30d_rep,  ax_30d_rep  = plt.subplots(nrows=2, ncols=4, figsize=(36, 13), dpi=dpi)
    fig_30d_rep.subplots_adjust(hspace=0.1, wspace=0.15)
    fig_365d_rep, ax_365d_rep = plt.subplots(nrows=2, ncols=4, figsize=(36, 13), dpi=dpi)
    fig_365d_rep.subplots_adjust(hspace=0.1, wspace=0.15)
    
    # Get list of observation files for the report
    flist_rep = sorted(glob.glob("%s_var*_passive_checks.csv" %o_type))

    # Retrieve variable number
    obs_varno = []
    for frep in flist_rep:
        obs_varno.append(find_between(frep, "var", "_passive"))
       
    # Select last 365 days and 30 days of data, summing over days. The defined arrays
    # have daily data (rows) for each observation type (column) 
    nobs                    = len(obs_varno)
    lst365d_tot, lst30d_tot = np.zeros((diff_365d, nobs)), np.zeros((diff_30d, nobs))
    lst365d_act, lst30d_act = np.zeros((diff_365d, nobs)), np.zeros((diff_30d, nobs))
    lst365d_pas, lst30d_pas = np.zeros((diff_365d, nobs)), np.zeros((diff_30d, nobs))
    lst365d_rej, lst30d_rej = np.zeros((diff_365d, nobs)), np.zeros((diff_30d, nobs))
    for ov in range(len(obs_varno)):
        # Read data stored on csv file
        frep = "%s/%s_var%s.csv" %(folder, o_type, obs_varno[ov])
        datetime, tot_obs, act_obs, pas_obs, rej_obs = read_from_csv(frep, 'summary')

        # Select data
        lst30d_tot[:, ov], lst365d_tot[:, ov] = select_daydata(datetime, tot_obs, 'state')
        lst30d_act[:, ov], lst365d_act[:, ov] = select_daydata(datetime, act_obs, 'state')
        lst30d_pas[:, ov], lst365d_pas[:, ov] = select_daydata(datetime, pas_obs, 'state')
        lst30d_rej[:, ov], lst365d_rej[:, ov] = select_daydata(datetime, rej_obs, 'state')

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # PLOT OBSERVATION DATA FOR LAST 30 DAYS: NUMBER OF OBSERVATIONS AND PERCENTAGE
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # Plot number of observations (total, active, passive, rejected)
    print("   + Plot last  30 days of data, from %s to %s" %(dt_30dbf, dt_prev_day))
    stack_barplot(ax_30d_rep[0,0], lst30d_dt, np.transpose(lst30d_tot), cols_ot)
    stack_barplot(ax_30d_rep[0,1], lst30d_dt, np.transpose(lst30d_act), cols_ot)
    stack_barplot(ax_30d_rep[0,2], lst30d_dt, np.transpose(lst30d_pas), cols_ot)
    stack_barplot(ax_30d_rep[0,3], lst30d_dt, np.transpose(lst30d_rej), cols_ot)

    # Plot percentage (total, active, passive, rejected)
    lst30d_tot_pc = calc_perc(lst30d_tot, lst30d_tot.sum(axis=1)[:,None])
    lst30d_act_pc = calc_perc(lst30d_act, lst30d_act.sum(axis=1)[:,None])
    lst30d_pas_pc = calc_perc(lst30d_pas, lst30d_pas.sum(axis=1)[:,None])
    lst30d_rej_pc = calc_perc(lst30d_rej, lst30d_rej.sum(axis=1)[:,None])
    stack_barplot(ax_30d_rep[1,0], lst30d_dt, np.transpose(lst30d_tot_pc), cols_ot)
    stack_barplot(ax_30d_rep[1,1], lst30d_dt, np.transpose(lst30d_act_pc), cols_ot)
    stack_barplot(ax_30d_rep[1,2], lst30d_dt, np.transpose(lst30d_pas_pc), cols_ot)
    stack_barplot(ax_30d_rep[1,3], lst30d_dt, np.transpose(lst30d_rej_pc), cols_ot)

    # Set title, labels and ticks
    arr_temp = [lst30d_tot, lst30d_act, lst30d_pas, lst30d_rej]
    for ind in range(4):
        maxval   = 1.1*np.amax(arr_temp[ind].sum(axis=1))
        if ind == 0:
            axis_labels_ticks(ax_30d_rep[0,ind], dt_30dbf, dt_prev_day, 0, maxval,
                              title=head_sum[ind+2], ylabel='Number of observations')
            axis_labels_ticks(ax_30d_rep[1,ind], dt_30dbf, dt_prev_day, 0, 100,
                              xlabel='Date and Time', ylabel='Percentage [%]',
                              xaxis_values=True, xfreq='3d', xfmt=fmt_30d)
        else:
            axis_labels_ticks(ax_30d_rep[0,ind], dt_30dbf, dt_prev_day, 0, maxval, 
                              title=head_sum[ind+2])
            axis_labels_ticks(ax_30d_rep[1,ind], dt_30dbf, dt_prev_day, 0, 100,
                              xlabel='Date and Time', xaxis_values=True,
                              xfreq='3d', xfmt=fmt_30d)

    # Legend
    handles_30d_rep = []
    for ov in range(len(obs_varno)):
        handles_30d_rep.append(Line2D([0], [0], color=cols_ot[ov], linewidth=15, 
                               label=var_dict[int(obs_varno[ov])]))
    ncolumn     = 4
    anchor_y    =  -(0.1 + 0.02*(np.ceil(len(handles_30d_rep)/ncolumn)-1))
    leg_30d_rep = fig_30d_rep.legend(loc='center', handles=handles_30d_rep, 
                        handlelength=3, ncol=ncolumn, bbox_to_anchor=(0.5, anchor_y), 
                        prop={'size': size+2})
    fig_30d_rep.gca().add_artist(leg_30d_rep)

    # Plot title and save
    plot_title_and_save(fig_30d_rep, "%s: observations" %o_type, '30 days',  dt_30dbf,
                        dt_prev_day-dt.timedelta(days=1), 'last30d_%s.png' %o_type)

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # PLOT OBSERVATION DATA FOR LAST 365 DAYS: NUMBER OF OBSERVATIONS NAD PERCENTAGE
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # Plot number of observations (total, active, passive, rejected)
    print("   + Plot last 365 days of data, from %s to %s" %(dt_365dbf, dt_prev_day))
    stack_barplot(ax_365d_rep[0,0], lst365d_dt, np.transpose(lst365d_tot), cols_ot)
    stack_barplot(ax_365d_rep[0,1], lst365d_dt, np.transpose(lst365d_act), cols_ot)
    stack_barplot(ax_365d_rep[0,2], lst365d_dt, np.transpose(lst365d_pas), cols_ot)
    stack_barplot(ax_365d_rep[0,3], lst365d_dt, np.transpose(lst365d_rej), cols_ot)

    # Plot percentage (total, active, passive, rejected)
    lst365d_tot_pc = calc_perc(lst365d_tot, lst365d_tot.sum(axis=1)[:,None])
    lst365d_act_pc = calc_perc(lst365d_act, lst365d_act.sum(axis=1)[:,None])
    lst365d_pas_pc = calc_perc(lst365d_pas, lst365d_pas.sum(axis=1)[:,None])
    lst365d_rej_pc = calc_perc(lst365d_rej, lst365d_rej.sum(axis=1)[:,None])
    stack_barplot(ax_365d_rep[1,0], lst365d_dt, np.transpose(lst365d_tot_pc), cols_ot)
    stack_barplot(ax_365d_rep[1,1], lst365d_dt, np.transpose(lst365d_act_pc), cols_ot)
    stack_barplot(ax_365d_rep[1,2], lst365d_dt, np.transpose(lst365d_pas_pc), cols_ot)
    stack_barplot(ax_365d_rep[1,3], lst365d_dt, np.transpose(lst365d_rej_pc), cols_ot)

    # Set title, labels and ticks
    arr_temp = [lst365d_tot, lst365d_act, lst365d_pas, lst365d_rej]
    for ind in range(4):
        maxval   = 1.1*np.amax(arr_temp[ind].sum(axis=1))
        if ind == 0:
            axis_labels_ticks(ax_365d_rep[0,ind], dt_365dbf, dt_prev_day, 0, maxval,
                              title=head_sum[ind+2], ylabel='Number of observations')
            axis_labels_ticks(ax_365d_rep[1,ind], dt_365dbf, dt_prev_day, 0, 100,
                              xlabel='Date and Time', ylabel='Percentage [%]',
                              xaxis_values=True, xfreq='30d', xfmt=fmt_365d)
        else:
            axis_labels_ticks(ax_365d_rep[0,ind], dt_365dbf, dt_prev_day, 0, maxval,
                              title=head_sum[ind+2])
            axis_labels_ticks(ax_365d_rep[1,ind], dt_365dbf, dt_prev_day, 0, 100,
                              xlabel='Date and Time', xaxis_values=True,
                              xfreq='30d', xfmt=fmt_365d)

    # Legend
    handles_365d_rep = []
    for ov in range(len(obs_varno)):
        handles_365d_rep.append(Line2D([0], [0], color=cols_ot[ov], linewidth=15,
                               label=var_dict[int(obs_varno[ov])]))
    ncolumn      = 4
    anchor_y     =  -(0.1 + 0.02*(np.ceil(len(handles_365d_rep)/ncolumn)-1))
    leg_365d_rep = fig_365d_rep.legend(loc='center', handles=handles_365d_rep,
                        handlelength=3, ncol=ncolumn, bbox_to_anchor=(0.5, anchor_y),
                        prop={'size': size+2})
    fig_365d_rep.gca().add_artist(leg_365d_rep)

    # Plot title and save
    plot_title_and_save(fig_365d_rep, "%s: observations" %o_type, '365 days',  
                        dt_365dbf, dt_prev_day-dt.timedelta(days=1), 
                        'last365d_%s.png' %o_type)


# -------------------------------------------------------------------------------------
# PLOT CHECK DATA FOR EACH REPORT
# -------------------------------------------------------------------------------------
print('\nCHECK DATA FOR EACH REPORT')
for o_type in report:
    # Initialize plots
    print('- %s:' %o_type)
    fig_30d_chk,  ax_30d_chk  = plt.subplots(nrows=2, ncols=2, figsize=(28, 13), dpi=dpi)
    fig_30d_chk.subplots_adjust(hspace=0.1, wspace=0.15)
    fig_365d_chk, ax_365d_chk = plt.subplots(nrows=2, ncols=2, figsize=(28, 13), dpi=dpi)
    fig_365d_chk.subplots_adjust(hspace=0.1, wspace=0.15)

    # File containing checks
    fpas = "%s/%s_passive_checks.csv"  %(folder, o_type)
    frej = "%s/%s_rejected_checks.csv" %(folder, o_type)
    datetime_pas, checks_pas = read_from_csv(fpas, 'checks', check_list=chk_list)
    datetime_rej, checks_rej = read_from_csv(frej, 'checks', check_list=chk_list)

    # Select last 365 days and 30 days of data, summing over days. The defined matrices
    # have daily data (roes) for each check number (column)
    lst30d_chk_pas  = np.zeros((diff_30d,  len(chk_dict)))
    lst30d_chk_rej  = np.zeros((diff_30d,  len(chk_dict)))
    lst365d_chk_pas = np.zeros((diff_365d, len(chk_dict)))
    lst365d_chk_rej = np.zeros((diff_365d, len(chk_dict)))
    lst30d_chk_pas, lst365d_chk_pas = select_daydata(datetime_pas, checks_pas, 'check')
    lst30d_chk_rej, lst365d_chk_rej = select_daydata(datetime_rej, checks_rej, 'check')

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # PLOT CHECK DATA FOR LAST 30 DAYS: NUMBER OF OBSERVATIONS NAD PERCENTAGE
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # Get column in which there is al least a non-zero element in one of the two arrays
    # in order to employ the same colour for the same check
    print("   + Plot last  30 days of data, from %s to %s" %(dt_30dbf, dt_prev_day))
    sum30d_ind_chk = np.sum(lst30d_chk_pas, axis=0) + np.sum(lst30d_chk_rej, axis=0)
    lst30d_ind_chk = np.where(sum30d_ind_chk > 0)[0]

    # Plot number of checks
    lst30d_plot_cpas = lst30d_chk_pas[:, lst30d_ind_chk]
    lst30d_plot_crej = lst30d_chk_rej[:, lst30d_ind_chk]
    stack_barplot(ax_30d_chk[0,0], lst30d_dt, np.transpose(lst30d_plot_cpas), cols_ot)
    stack_barplot(ax_30d_chk[0,1], lst30d_dt, np.transpose(lst30d_plot_crej), cols_ot)

    # Plot percentage of checks
    lst30d_plot_cpas_pc = np.transpose(calc_perc(lst30d_plot_cpas, 
                                    lst30d_plot_cpas.sum(axis=1)[:,None]))
    lst30d_plot_crej_pc = np.transpose(calc_perc(lst30d_plot_crej, 
                                    lst30d_plot_crej.sum(axis=1)[:,None]))
    stack_barplot(ax_30d_chk[1,0], lst30d_dt, lst30d_plot_cpas_pc, cols_ot)
    stack_barplot(ax_30d_chk[1,1], lst30d_dt, lst30d_plot_crej_pc, cols_ot)

    # Set title, labels and ticks
    arr_temp = [lst30d_plot_cpas, lst30d_plot_crej]
    tit_temp = ["Passive", "Rejected"]
    for ind in range(2):
        maxval   = 1.1*np.amax(arr_temp[ind].sum(axis=1))
        if ind == 0:
            axis_labels_ticks(ax_30d_chk[0,ind], dt_30dbf, dt_prev_day, 0, maxval,
                              title=tit_temp[ind], ylabel='Number of observations')
            axis_labels_ticks(ax_30d_chk[1,ind], dt_30dbf, dt_prev_day, 0, 100,
                              xlabel='Date and Time', ylabel='Percentage [%]',
                              xaxis_values=True, xfreq='3d', xfmt=fmt_30d)
        else:
            axis_labels_ticks(ax_30d_chk[0,ind], dt_30dbf, dt_prev_day, 0, maxval,
                              title=tit_temp[ind])
            axis_labels_ticks(ax_30d_chk[1,ind], dt_30dbf, dt_prev_day, 0, 100,
                              xlabel='Date and Time', xaxis_values=True,
                              xfreq='3d', xfmt=fmt_30d)

    # Legend
    handles_30d_chk = []
    for ov in range(len(lst30d_ind_chk)):
        handles_30d_chk.append(Line2D([0], [0], color=cols_ot[ov], linewidth=15,
                               label=chk_dict[int(lst30d_ind_chk[ov])]))
    ncolumn     = 3
    anchor_y    =  -(0.1 + 0.02*(np.ceil(len(handles_30d_chk)/ncolumn)-1))
    leg_30d_chk = fig_30d_chk.legend(loc='center', handles=handles_30d_chk,
                        handlelength=3, ncol=ncolumn, bbox_to_anchor=(0.5, anchor_y),
                        prop={'size': size+2})
    fig_30d_chk.gca().add_artist(leg_30d_chk)

    # Plot title and save
    plot_title_and_save(fig_30d_chk, "%s: checks for non assimilated observations" \
                        %o_type, '30 days',  dt_30dbf, dt_prev_day-dt.timedelta(days=1), 
                        'last30d_%s_check.png' %o_type)

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # PLOT CHECK DATA FOR LAST 365 DAYS: NUMBER OF OBSERVATIONS AND PERCENTAGE
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    # Get column in which there is al least a non-zero element in one of the two arrays
    # in order to employ the same colour for the same check
    print("   + Plot last 365 days of data, from %s to %s" %(dt_365dbf, dt_prev_day))
    sum365d_ind_chk = np.sum(lst365d_chk_pas, axis=0) + np.sum(lst365d_chk_rej, axis=0)
    lst365d_ind_chk = np.where(sum365d_ind_chk > 0)[0]

    # Plot number of checks
    lst365d_plot_cpas = lst365d_chk_pas[:, lst365d_ind_chk]
    lst365d_plot_crej = lst365d_chk_rej[:, lst365d_ind_chk]
    stack_barplot(ax_365d_chk[0,0], lst365d_dt, np.transpose(lst365d_plot_cpas), cols_ot)
    stack_barplot(ax_365d_chk[0,1], lst365d_dt, np.transpose(lst365d_plot_crej), cols_ot)

    # Plot percentage of checks
    lst365d_plot_cpas_pc = np.transpose(calc_perc(lst365d_plot_cpas,
                                    lst365d_plot_cpas.sum(axis=1)[:,None]))
    lst365d_plot_crej_pc = np.transpose(calc_perc(lst365d_plot_crej,
                                    lst365d_plot_crej.sum(axis=1)[:,None]))
    stack_barplot(ax_365d_chk[1,0], lst365d_dt, lst365d_plot_cpas_pc, cols_ot)
    stack_barplot(ax_365d_chk[1,1], lst365d_dt, lst365d_plot_crej_pc, cols_ot)

    # Set title, labels and ticks
    arr_temp = [lst365d_plot_cpas, lst365d_plot_crej]
    tit_temp = ["Passive", "Rejected"]
    for ind in range(2):
        maxval   = 1.1*np.amax(arr_temp[ind].sum(axis=1))
        if ind == 0:
            axis_labels_ticks(ax_365d_chk[0,ind], dt_365dbf, dt_prev_day, 0, maxval,
                              title=tit_temp[ind], ylabel='Number of observations')
            axis_labels_ticks(ax_365d_chk[1,ind], dt_365dbf, dt_prev_day, 0, 100,
                              xlabel='Date and Time', ylabel='Percentage [%]',
                              xaxis_values=True, xfreq='30d', xfmt=fmt_365d)
        else:
            axis_labels_ticks(ax_365d_chk[0,ind], dt_365dbf, dt_prev_day, 0, maxval,
                              title=tit_temp[ind])
            axis_labels_ticks(ax_365d_chk[1,ind], dt_365dbf, dt_prev_day, 0, 100,
                              xlabel='Date and Time', xaxis_values=True,
                              xfreq='30d', xfmt=fmt_365d)

    # Legend
    handles_365d_chk = []
    for ov in range(len(lst365d_ind_chk)):
        handles_365d_chk.append(Line2D([0], [0], color=cols_ot[ov], linewidth=15,
                               label=chk_dict[int(lst365d_ind_chk[ov])]))
    ncolumn      = 3
    anchor_y     =  -(0.1 + 0.02*(np.ceil(len(handles_365d_chk)/ncolumn)-1))
    leg_365d_chk = fig_365d_chk.legend(loc='center', handles=handles_365d_chk,
                        handlelength=3, ncol=ncolumn, bbox_to_anchor=(0.5, anchor_y),
                        prop={'size': size+2})
    fig_365d_chk.gca().add_artist(leg_365d_chk)

    # Plot title and save
    plot_title_and_save(fig_365d_chk, "%s: checks for non assimilated observations" \
                        %o_type, '365 days',  dt_365dbf, dt_prev_day-dt.timedelta(days=1), 
                        'last365d_%s_check.png' %o_type)
